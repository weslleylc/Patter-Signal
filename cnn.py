# -*- coding: utf-8 -*-
"""CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q7Zh9-HYmBiWjNYNDPV6DVWFC3qO5r3Q

## CNN [input imagem: output:time series]
"""

# import librarys for this applications
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from scipy.signal import butter, lfilter
from keras.models import Sequential
from keras.layers import Dense, Activation, Conv2D, Dropout, LSTM, Conv1D, MaxPooling1D, GRU, MaxPool2D, ELU
from keras.layers import MaxPooling2D, Flatten, RepeatVector, TimeDistributed, Reshape, BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
from keras.models import model_from_json
from keras.constraints import max_norm
from keras import optimizers
from os import listdir
from os.path import isfile, join
import cv2
from PIL import Image

"""## Funções de manipulação das imagens"""

def save(filepath, fig=None):
    '''Save the current image with no whitespace
    Example filepath: "myfig.png" or r"C:\myfig.pdf"
    '''
    import matplotlib.pyplot as plt
    if not fig:
        fig = plt.gcf()

    plt.subplots_adjust(0, 0, 1, 1, 0, 0)
    for ax in fig.axes:
        ax.axis('off')
        ax.margins(0, 0)
        ax.xaxis.set_major_locator(plt.NullLocator())
        ax.yaxis.set_major_locator(plt.NullLocator())
    fig.savefig(filepath, pad_inches=0, bbox_inches='tight')


def generate_images_from_signals(signal, width, heigth, name, min_v=-1.3,
                                 max_v=1.8, directory="images/", plot=False):
    fig = plt.figure()
    plt.plot(signal)
    plt.xticks([]), plt.yticks([])
    plt.ylim(min_v, max_v)
    for spine in plt.gca().spines.values():
        spine.set_visible(False)
    if plot:
        plt.show()
    filepath = directory + name + '.png'
    save(filepath, fig=fig)
    im_gray = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
    im_gray = cv2.resize(im_gray, (width, heigth),
                         interpolation=cv2.INTER_LANCZOS4)
    ret, thresh = cv2.threshold(im_gray, 127, 255,
                                cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    cv2.imwrite(filepath, thresh)
    plt.close()
    pd.DataFrame(signal).to_csv(directory + name + '.csv', index=False)


def read_image_signal(filename, directory="images/"):
    im_gray = cv2.imread(directory + filename + '.png', cv2.IMREAD_GRAYSCALE)
    ret, thresh = cv2.threshold(im_gray, 127, 255,
                                cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    signal = pd.read_csv(directory + filename + '.csv').values
    return thresh, signal.flatten()

  
def read_images_from_directory(directory="images/"):
    files = [f for f in listdir(directory) if isfile(join(directory, f))]
    images = []
    for filename in files:
        im_gray = cv2.imread(directory + filename,
                             cv2.IMREAD_GRAYSCALE)
        ret, thresh = cv2.threshold(im_gray, 127, 255,
                                    cv2.THRESH_BINARY | cv2.THRESH_OTSU)
        images.append(thresh)
    return np.array(images)

"""## Lendo os dados"""

#read data
list_ecg = pd.read_csv('ecg.csv').drop(['Unnamed: 0'], axis=1).values
fs = 360
width = 350
heigth = 680
list_ecg = np.array(list_ecg)

"""## Gerando imagens dos sinais"""

# run separatly to save memory
# custom_range = range(0, 15, 1)
# custom_range = range(14, 30, 1)
custom_range = range(0, 30, 4)

# generate pairs
for i in custom_range:
    for j in range(len(list_ecg)):
        generate_images_from_signals(list_ecg[j, i:i+70], width, heigth,
                                     str(i) + "_" + str(j))

# read pairs(image, signal)
images = []
signals =[]
X = []
for i in custom_range:
    for j in range(len(list_ecg)):
        image, signal = read_image_signal(str(i) + "_" + str(j))
        signals.append(signal)
        images.append(image)
        X.append(cv2.bitwise_not(image)/255)
images = np.array(images)
signals = np.array(signals)
X = np.array(X)

# Filters
min_v = -1.5
max_v = 2
conv_filter = np.linspace(min_v, max_v, heigth)

x=X[0]
x_series=[]
for i in range(width):
    x_series.append(np.mean(x[:,i] * conv_filter))
x_signal=[]
for i in range(0, width, 5):
    x_signal.append(np.max(x_series[i:i+5]))
binimagem = Image.fromarray(images[0])
binimagem


"""## Pré-Processamento"""

n_in = len(X)
# X = read_images_from_signals("images/")
X = X.reshape(n_in, 1, heigth, width)
# get the shape of input
input_shape = X.shape

"""## Divisão treino/test"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, signals, test_size=0.33, random_state=42)


"""## Comparando os sinais originais com as imagens transformadas em sinais[Conjunto de treino]"""

def smooth(y, box_pts):
    box = np.ones(box_pts)/box_pts
    y_smooth = np.convolve(y, box, mode='same')
    return y_smooth

# comparasion between the original input and the output
for i in range(0, len(X_train), 100):
    original = y_train[i]
    input_image = X_train[i].reshape(1, 1, 680, 350)
    output_signal = model.predict(input_image).flatten()
    plt.plot(original, '-b', label = "Saída original")
    plt.plot(output_signal, '-r', label = "Saída")
    plt.plot(smooth(output_signal, 3), 'g', label = "Saída suavizada")
    plt.legend()
    plt.show()
    plt.close()

"""## Comparando os sinais originais com as imagens transformadas em sinais[Conjunto de teste]"""

# comparasion between the original input and the output
for i in range(0, len(X_test), 100):
    original = y_test[i]
    input_image = X_test[i].reshape(1, 1, 680, 350)
    output_signal = model.predict(input_image).flatten()
    plt.plot(original, '-b', label = "Saída original")
    plt.plot(output_signal, '-r', label = "Saída")
    plt.plot(smooth(output_signal, 3), 'g', label = "Saída suavizada")
    plt.legend()
    plt.show()
    plt.close()

"""## Data Augmentation [random zoom, width_shift_range widtih, height_shift_range]"""

# data augmentation
width_shift_range = 0.1
height_shift_range = 0.1
zoom_range = [0.9, 1.1]
datagen = ImageDataGenerator(width_shift_range=width_shift_range,
                             height_shift_range=height_shift_range,
                             zoom_range=zoom_range,
                             data_format='channels_first')
# fit parameters from data
datagen.fit(images.reshape(len(images), 1, heigth, width))
# configure batch size and retrieve one batch of images
for i, X_batch in enumerate(datagen.flow(images.reshape(len(images), 1, heigth, width),
                                         batch_size=8,
                                         save_to_dir='cloned_images',
                                         save_prefix='aug',
                                         save_format='png')):
    if i > 3:
        break
print("Data augmentation generated")

data_augmentation = read_images_from_directory("cloned_images/")

data_augmentation = np.array([cv2.bitwise_not(x) for x in data_augmentation])
data_augmentation = data_augmentation.reshape(len(data_augmentation),
                                              1, heigth, width)
data_augmentation = data_augmentation/255  # normalize

def smooth(y, box_pts):
    box = np.ones(box_pts)/box_pts
    y_smooth = np.convolve(y, box, mode='same')
    return y_smooth

"""## Aplicando o modelo nos dados gerados artificialmente"""

# plt the signal for data augmentation
for i in range(0, len(data_augmentation), 4):
    input_image = data_augmentation[i].reshape(1, 1, 680, 350)
    output_signal = model.predict(input_image).flatten()
    plt.plot(output_signal, '-r', label = "Saída")
    plt.plot(smooth(output_signal, 3), 'g', label = "Saída suavizada")
    plt.legend()
    plt.show()
    plt.close()

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model.h5")
print("Saved model to disk")
